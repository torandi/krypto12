\documentclass[a4paper,11pt]{article}

\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage[english, english]{babel}
\usepackage{parskip}

\usepackage{rapportfram}

\author{Andreas Tarandi\\890416-0317}
\title{Homework C}
\titleextra{Study group: Peter Boström and Meidi Tönisson}
\course{DD2448}

\begin{document}
	\maketitle

	\section*{1. }
		\subsection*{a) DH implies DL}
			Assume there exists an adversary $A_{DL}$ such that
			$ A_{DL}(g, y) = log_g{y} $, that is that the DL-assumption does not hold.
		
			If we choose $g^x$ as $y$ then $A_{DL}(g, g^x) = log_g{g^x} = x$

			But then we can write the DH-adversary as $A_{DH}(g^a, g^b) = g^{ab} = g^{a log_g{g^b}} = g^{a * A_{DL}(g, g^b)} $, that is as a function of the DL-adversary. 

			But then since we in (1) assumed that $A_{DL}$ exists, $A_{DH}$ will also exist.

			This means that if the DL-implication does not hold, then neither does the DH-implication: $\neg DL \to \neg DH $. 

			We can then apply the rule of transposition ($\neg P \to \neg Q \vdash Q \to P$) and we have $DH \to DL$ \\
			\\
			Q.E.D.
			
	\subsection*{b) DDH implies DH }
		
	Assume there exists an adversary $A_{DH}$ such that $ A_{DH}(g^a, g^b) = g^{ab}$, that is, the DH-assumption does not hold. (2)

	Then if we create an DDH-adversary $A_{DDH} (a, b, c) = (c == A_{DH} (a, b)$,
	we can distinguish between the probability distribution for $Pr [ A_{DDH}(g^a, g^b, g^{ab}) = 1] $ from the one for $ Pr [ A_{DDH}(g^a, g^b, g^c) = 1 ] $, meaning that DDH-does not hold.

	We have that $\neg DH \to \neg DDH$, and by once again applying the rule of transposition we get $DDH \to DH$. \\
	\\
	Q.E.D.

	\section*{2. }

	\subsection*{a)}

	$ \psi(g^a, g^b) = \psi(g, g)^{ab}$ (1)\\
	$ \psi(g^1, g^c) = \psi(g, g)^{1*c}$ (2)\\
	Since we know that $\psi(g, g) \neq 1$ we can just compare the result from (1) and (2) to determine the outcome. If they are equal then $ ab \equiv c$.
	Therefore the Diffie-Hellman decision problem is when using the map.

	\subsection*{b) }
	In a generalized three party Diffie-Hellman key exchange using the map each part would 
	start by sending $g$ raised to his exponent to the two other parts.

	Each part will then have his own exponent and $g$ raised to the two others separatly.
	If he then inputs the two values from the other parts into the map and raises the output
	to his own exponend he will have the secret key.

	Example: (A's calculations):\\
	$ \psi(g^b, g^c)^a = \psi(g, g)^{bca} = \psi(g, g)^{abc} $

	\subsection*{c) }
	The decision Diffie-Hellman problem under which our scheme would be secure is as follows:
	In a group $G$ of prime order $p$ with generator $g$ and $a, b, c, d \in Z_q$ randomly chosen then for every polynomial time algorithm $A$\\
	$|Pr [ A(g^a, g^b, g^c, g^{abc}) = 1 ] - Pr [ A(g^a, g^b, g^c, g^d) = 1] | $ is negligible.

	\subsection*{d) }
	Assume that a man-in-the-middle intercepts all traffic between the parts. He would have a
	own private exponent and have a separate key for each channel to the parts. For each channel
	he recives a public value ($g^x$, $x \in {a, b}$) and then sends one of the other parts public value ($g^y$, $y \in {a,b}$, $y \neq x$) and his own public value($g^z$). 
	The key for that channel then becomes $\psi(g^x, g^y)^z$. Using this techique all the parts
	will be under the assumption that they communicate with each other while they in fact are
	communicating through a fourth part.

	One thing that might tell the parts that something is wrong is if all the communication 
	comes from the same IP-address, so the man-in-the-middle would probably have to use two
	separatly adresses.


	\section*{3. }
	\subsection*{a) }
	
	The chinese remainder theorem gives that given a group $Z^*_N$ with $N=pq$ we have
	$Z^*_N \cong Z^*_p \times Z^*_q$.

	The identity in the direct product of two groups $G$ and $H$ are $(1_G, 1_H)$, in our
	case $(1, 1)$.

	The order of an element in the direct product must be a multiple of
	the order of both the sub elements since they need to be identity when raised to the
	order of the composit element. The smallest number fullfulling this is the lcm of
	both the orders.
	This is also one of the elementary properties of the direct product of two groups.

	Thus $ ord_N(a) = lcm(ord_p(a), ord_q(a)) $.

	O.E.D.

	\subsection*{b) }
	Given\\
	$gcd(p-1, q-1) = d$ (1)\\
	$\phi(N) = (p-1)(q-1)$ (2)\\
	Then we shall prove the following:
	$ord_N(a) = \frac{\phi(N)}{d}$ (3)\\
	Substitute (1) and (2) into (3):\\
	$ ord_N(a) = \frac{(p-1)(q-1)}{gcd(p-1, q-1)} $\\ 
	But $ a*b = gcd(a, b) * lcm(a, b)$ (4) \\
	so $ ord_N(a) = \frac{gcd(p-1, q-1)*lcm(p-1, q-1)}{gcd(p-1, q-1)} = lcm(p-1, q-1)$ (5)\\
	
	In 3a we proved that $ ord_N(a) = lcm(ord_p(a), ord_q(a)) $, so
	$ord_p(a) = p-1 $ and $ord_q(a) = q-1$ (6) \\
	holds iff there exists such elements as in (5).

	But $Z^*_p$ and $Z^*_q$ are both cyclic groups of order $p-1$ and $q-1$,
	so they must contain at least one element that generates the group, 
	and thus having order $p-1$ resp. $q-1$. Since $Z^*_N$ is isomorphic to $Z^*_p \times Z^*_q$,
	it will contain this element, making (6) true, and therefore also (5) and in turn (3).

	Q.E.D.

	\section*{5. }

	\subsection*{b) }
	Assume that the RSA assumption does not hold. That is, given a random cipher text and
	public key it is easy to find the plaintext.
	
	In the strong RSA assumption we are allowed to choose a public exponent. But since it was
	easy to find the plaintext given any random public key, it will also be easy to find
	it if we are allowed to choose a public key. We could even randomize the exponent
	and then use the same method we used for solving the the RSA problem.

	Thus we have $\neg $ RSA assumption $ \to \neg $ strong RSA assumption\\
	and just as in 1) we can use the rule of transposition to get\\
	strong RSA assumption $ \to $ RSA assumption\\

	Q.E.D.

	\section*{6. }
	If we assume that we just wish to forge a signature on any message other than the authentic
	messages (existential forgery), and consider the case where the messages just differ from 
	each other with one single bit (per unique message). We will then need at least three 
	messages to be able to forge a forth different from the other two.

	We would then save the parts of the private key we recive in the signature and map
	them to the corresponding bit-value in the message.

	If we instead would wish to perform an selective forgery, that is signing any message
	of our own choice, we would need the whole key. The key consist of 512 numbers, of which
	the first 256 is revealed in the first signature. If we then assume that each message
	will differ from the other in about half the bits we will get an exponential decreasing
	number of bits each time. This gives us the following revealed bits:\\
	$256 + 128 + 64 + 32 + 16 + 8 + 4 + 2 + 1 + 1= 511$\\
	So following this reasoning we would be lacking just one bit after nine messages, so we
	can estimate that given ten messages we will probalisticaly have the key, We can assume
	this to be the average case.

	If we instead consider the worst case senario we will only get one extra bit for every
	new message after the first one. If would then take 257 message until we have the full
	key. This is the upper bound.

	In the best case scenario the two first messages will differ in all the bits, and thus
	we will have the full key after only two messages.

	Summarizing we would need at most 257 messages, on average 10 messages and at least two
	messages to get the full key.

		

\end{document}
